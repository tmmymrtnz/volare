{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TP3 - Modelado y prototipo de estimación de tarifas aéreas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1903f2a",
      "metadata": {},
      "source": [
        "## 1. Introducción\n",
        "En este cuaderno desarrollamos el flujo completo para estimar la tarifa de vuelos domésticos en India. Trabajamos con el archivo `dataset/Cleaned_dataset.csv`, definimos el problema como una regresión supervisada y avanzamos con preparación de datos, entrenamiento de modelos y desarrollo de un prototipo funcional.\n",
        "\n",
        "Desde el punto de vista de negocio, el modelo apunta a responder preguntas como: *¿este vuelo está caro o barato respecto a vuelos similares?* y *¿cómo cambia el precio esperado si modifico aerolínea, cantidad de escalas o días de anticipación?*. Este tipo de herramienta podría utilizarse tanto por un usuario final (comparar alternativas de compra) como por una aerolínea o agencia online para entender la sensibilidad del precio frente a distintas decisiones comerciales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b6dd85",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
        "from sklearn.model_selection import (\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    TimeSeriesSplit,\n",
        "    cross_validate,\n",
        "    learning_curve,\n",
        ")\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "from volare_model.pipeline import FeatureGenerator, build_pipeline, build_preprocessor\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "sns.set_theme(style=\"whitegrid\", context=\"talk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76da47a0",
      "metadata": {},
      "source": [
        "### 1.1 Configuración inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43cbdd2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = Path(\"dataset/Cleaned_dataset.csv\")\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "REPORTS_DIR = Path(\"reports\")\n",
        "RANDOM_STATE = 42\n",
        "VALIDATION_RATIO = 0.2\n",
        "CV_SAMPLE_TARGET = 120_000  # filas máximas para CV/HP tuning\n",
        "\n",
        "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
        "REPORTS_DIR.mkdir(exist_ok=True)\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd6fae3",
      "metadata": {},
      "source": [
        "### 1.2 Carga del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e134c613",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_raw = pd.read_csv(DATA_PATH)\n",
        "df = df_raw.copy()\n",
        "print(f\"Registros totales: {df.shape[0]:,} | Columnas: {df.shape[1]}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c66e341f",
      "metadata": {},
      "source": [
        "### 1.3 Exploración general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077d3316",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n",
        "\n",
        "df.select_dtypes(include=np.number).describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407a2ab6",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "axes[0].hist(df[\"Fare\"], bins=40, color=\"#4c72b0\")\n",
        "axes[0].set_title(\"Distribución de tarifas (Fare)\")\n",
        "axes[0].set_xlabel(\"Fare\")\n",
        "axes[1].hist(df[\"Duration_in_hours\"], bins=40, color=\"#dd8452\")\n",
        "axes[1].set_title(\"Duración de vuelo (horas)\")\n",
        "axes[1].set_xlabel(\"Duration_in_hours\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c124b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_cols = [\"Airline\", \"Source\", \"Destination\", \"Total_stops\", \"Class\"]\n",
        "for col in cat_cols:\n",
        "    display(pd.DataFrame({\"categoria\": df[col].value_counts().index,\n",
        "                          \"frecuencia\": df[col].value_counts().values}).head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ca7aea",
      "metadata": {},
      "source": [
        "> Observamos una concentración de vuelos con origen Delhi/Mumbai, presencia de múltiples aerolíneas y predominio de rutas sin escalas. Las tarifas muestran una distribución sesgada a la derecha, lo que sugiere la conveniencia de usar métricas robustas como MAE para evaluar el rendimiento de los modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ea759d",
      "metadata": {},
      "source": [
        "### 1.4 Calidad de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188da729",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e5f4a36",
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicate_cols = [\n",
        "    \"Date_of_journey\", \"Airline\", \"Flight_code\", \"Source\",\n",
        "    \"Destination\", \"Departure\", \"Arrival\", \"Class\"\n",
        "]\n",
        "duplicated_rows = df.duplicated(subset=duplicate_cols).sum()\n",
        "print(f\"Duplicados detectados: {duplicated_rows}\")\n",
        "df = df.drop_duplicates(subset=duplicate_cols).reset_index(drop=True)\n",
        "print(f\"Dataset tras remover duplicados: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b24facc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ordenamos temporalmente para mantener una validación más realista.\n",
        "df[\"journey_date_dt\"] = pd.to_datetime(df[\"Date_of_journey\"], errors=\"coerce\")\n",
        "df = df.sort_values(\"journey_date_dt\").reset_index(drop=True)\n",
        "df[[\"journey_date_dt\", \"Date_of_journey\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9d909bc",
      "metadata": {},
      "source": [
        "> Aplicamos una división temporal (80/20) para simular el uso real del modelo: entrenamos con las fechas más antiguas y dejamos las más recientes para validación. Esto reduce fugas de información respecto a un `train_test_split` aleatorio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cb4f217",
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = [\"Fare\", \"Duration_in_hours\", \"Days_left\"]\n",
        "\n",
        "quantiles = df[numeric_cols].quantile([0.01, 0.99])\n",
        "\n",
        "print(\"Percentiles 1% y 99%:\\n\", quantiles)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "sns.boxplot(data=df[numeric_cols], orient=\"h\")\n",
        "\n",
        "plt.title(\"Boxplot de variables numéricas\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63e384a",
      "metadata": {},
      "source": [
        "Los outliers son esperables por tratarse de tarifas aéreas y duraciones variables según la ruta. No los eliminaremos para conservar la variabilidad, pero los tendremos presentes cuando evaluemos los errores."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbf9329e",
      "metadata": {},
      "source": [
        "### 1.5 Feature engineering y preprocesamiento\n",
        "El pipeline definido en `volare_model.pipeline` enriquece el dataset con:\n",
        "- Variables temporales (mes, día de la semana, fin de semana, temporada y feriados indios).\n",
        "- Indicadores de anticipación (`is_last_minute`, `is_early_booking`) y métricas derivadas como `duration_per_stop`.\n",
        "- Combinaciones categóricas (`route`, `route_class`) para capturar la interacción entre ruta y cabina.\n",
        "Todo se integra en un `ColumnTransformer` con imputación y escalado, lo que permite serializar el preprocesamiento completo junto al algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb8d1ba4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# La ingeniería de features y los pipelines reutilizables se importan desde\n",
        "# `volare_model.pipeline`. Ver ese módulo para el detalle de nuevas features\n",
        "# de calendario (temporada, feriados), combinaciones ruta-clase y las\n",
        "# transformaciones numéricas/categóricas utilizadas en el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "952ea0f6",
      "metadata": {},
      "source": [
        "### 1.6 División en train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08eac434",
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET = \"Fare\"\n",
        "time_split_idx = int(len(df) * (1 - VALIDATION_RATIO))\n",
        "\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X = X.drop(columns=[\"journey_date_dt\"], errors=\"ignore\")\n",
        "\n",
        "X_train = X.iloc[:time_split_idx].copy()\n",
        "X_test = X.iloc[time_split_idx:].copy()\n",
        "y_train = y.iloc[:time_split_idx].copy()\n",
        "y_test = y.iloc[time_split_idx:].copy()\n",
        "\n",
        "print(\n",
        "    f\"Train: {X_train.shape[0]:,} filas (hasta {df['journey_date_dt'].iloc[time_split_idx-1].date()})\"\n",
        ")\n",
        "print(\n",
        "    f\"Test:  {X_test.shape[0]:,} filas (desde {df['journey_date_dt'].iloc[time_split_idx].date()})\"\n",
        ")\n",
        "\n",
        "cv_window = min(len(X_train), CV_SAMPLE_TARGET)\n",
        "X_train_cv = X_train.iloc[-cv_window:].copy()\n",
        "y_train_cv = y_train.iloc[-cv_window:].copy()\n",
        "print(f\"Ventana usada para CV/HP tuning: {cv_window:,} filas más recientes\")\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f27c1c7e",
      "metadata": {},
      "source": [
        "### 1.7 Métricas auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5551a69a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def regression_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = root_mean_squared_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R2\": r2\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a220a49",
      "metadata": {},
      "source": [
        "### 1.8 Modelos baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f130af",
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_models = {\n",
        "    \"Dummy (mediana)\": DummyRegressor(strategy=\"median\"),\n",
        "    \"Regresión Ridge\": Ridge(alpha=1.0)\n",
        "}\n",
        "\n",
        "baseline_results = []\n",
        "trained_baselines = {}\n",
        "for name, estimator in baseline_models.items():\n",
        "    pipeline = build_pipeline(estimator)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    preds = pipeline.predict(X_test)\n",
        "    metrics = regression_metrics(y_test, preds)\n",
        "    metrics[\"modelo\"] = name\n",
        "    baseline_results.append(metrics)\n",
        "    trained_baselines[name] = pipeline\n",
        "\n",
        "baseline_df = pd.DataFrame(baseline_results)\n",
        "baseline_df[[\"modelo\", \"MAE\", \"RMSE\", \"R2\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d314b6bf",
      "metadata": {},
      "source": [
        "### 1.9 Modelos avanzados y validación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53bcb370",
      "metadata": {},
      "outputs": [],
      "source": [
        "advanced_models = [\n",
        "    (\"Random Forest\", RandomForestRegressor(\n",
        "        n_estimators=160,\n",
        "        max_depth=None,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )),\n",
        "    (\"XGBoost\", XGBRegressor(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=8,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.8,\n",
        "        objective=\"reg:squarederror\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        tree_method=\"hist\"\n",
        "    )),\n",
        "]\n",
        "\n",
        "scoring = {\n",
        "    \"mae\": \"neg_mean_absolute_error\",\n",
        "    \"rmse\": \"neg_root_mean_squared_error\",\n",
        "    \"r2\": \"r2\"\n",
        "}\n",
        "\n",
        "time_cv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "cv_summary = []\n",
        "for name, estimator in advanced_models:\n",
        "    pipeline = build_pipeline(estimator)\n",
        "    cv_scores = cross_validate(\n",
        "        pipeline,\n",
        "        X_train_cv,\n",
        "        y_train_cv,\n",
        "        scoring=scoring,\n",
        "        cv=time_cv,\n",
        "        n_jobs=-1,\n",
        "        error_score=\"raise\",\n",
        "        pre_dispatch=2\n",
        "    )\n",
        "    cv_summary.append({\n",
        "        \"modelo\": name,\n",
        "        \"MAE (CV)\": -cv_scores[\"test_mae\"].mean(),\n",
        "        \"RMSE (CV)\": -cv_scores[\"test_rmse\"].mean(),\n",
        "        \"R2 (CV)\": cv_scores[\"test_r2\"].mean()\n",
        "    })\n",
        "\n",
        "cv_results_df = pd.DataFrame(cv_summary)\n",
        "cv_results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c54c4e71",
      "metadata": {},
      "source": [
        "### 1.10 Búsqueda de hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be13052",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lookup = {name: estimator for name, estimator in advanced_models}\n",
        "\n",
        "best_row = cv_results_df.sort_values(\"MAE (CV)\").iloc[0]\n",
        "best_model_name = best_row[\"modelo\"]\n",
        "print(f\"Mejor modelo según CV: {best_model_name}\")\n",
        "\n",
        "param_spaces = {\n",
        "    \"Random Forest\": {\n",
        "        \"model__n_estimators\": [160, 240, 320],\n",
        "        \"model__max_depth\": [None, 18, 24],\n",
        "        \"model__min_samples_split\": [2, 4],\n",
        "        \"model__min_samples_leaf\": [1, 2],\n",
        "        \"model__max_features\": [None, \"sqrt\"],\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"model__n_estimators\": [300, 400, 500],\n",
        "        \"model__max_depth\": [6, 8],\n",
        "        \"model__learning_rate\": [0.03, 0.05],\n",
        "        \"model__subsample\": [0.8, 1.0],\n",
        "        \"model__colsample_bytree\": [0.7, 0.9],\n",
        "        \"model__gamma\": [0, 1],\n",
        "    },\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=build_pipeline(model_lookup[best_model_name]),\n",
        "    param_distributions=param_spaces[best_model_name],\n",
        "    n_iter=12,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=time_cv,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    pre_dispatch=2,\n",
        ")\n",
        "search.fit(X_train_cv, y_train_cv)\n",
        "\n",
        "print(f\"Mejor set de hiperparámetros: {search.best_params_}\")\n",
        "print(f\"MAE (CV) optimizado: {-search.best_score_:,.0f}\")\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "search_results_df = (\n",
        "    pd.DataFrame(search.cv_results_)\n",
        "    .sort_values(\"mean_test_score\", ascending=False)\n",
        "    [[\"mean_test_score\", \"std_test_score\", \"params\"]]\n",
        "    .head(5)\n",
        ")\n",
        "search_results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec4675a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Curva de aprendizaje (MAE) sobre la ventana temporal más reciente.\n",
        "lc_window = min(len(X_train), 60000)\n",
        "X_lc = X_train.iloc[-lc_window:]\n",
        "y_lc = y_train.iloc[-lc_window:]\n",
        "\n",
        "lc_train_sizes, lc_train_scores, lc_val_scores = learning_curve(\n",
        "    estimator=best_model,\n",
        "    X=X_lc,\n",
        "    y=y_lc,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
        "    cv=time_cv,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "lc_train_mae = -lc_train_scores.mean(axis=1)\n",
        "lc_val_mae = -lc_val_scores.mean(axis=1)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(lc_train_sizes, lc_train_mae, label=\"Train MAE\", marker=\"o\")\n",
        "plt.plot(lc_train_sizes, lc_val_mae, label=\"CV MAE\", marker=\"o\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.xlabel(\"Cantidad de muestras\")\n",
        "plt.title(\"Curva de aprendizaje (subset temporal reciente)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "551a6959",
      "metadata": {},
      "source": [
        "### 1.11 Evaluación en el conjunto de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423d77e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.fit(X_train, y_train)\n",
        "test_predictions = best_model.predict(X_test)\n",
        "final_metrics = regression_metrics(y_test, test_predictions)\n",
        "final_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed2b89e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_metrics_df = pd.DataFrame([{\"modelo\": f\"{best_model_name} (tuneado)\", **final_metrics}])\n",
        "metrics_summary = pd.concat(\n",
        "    [\n",
        "        baseline_df.assign(etapa=\"Baseline\"),\n",
        "        cv_results_df.rename(columns={\"MAE (CV)\": \"MAE\", \"RMSE (CV)\": \"RMSE\", \"R2 (CV)\": \"R2\"}).assign(etapa=\"CV\"),\n",
        "        test_metrics_df.assign(etapa=\"Test\"),\n",
        "    ],\n",
        "    ignore_index=True,\n",
        ")\n",
        "metrics_summary[[\"etapa\", \"modelo\", \"MAE\", \"RMSE\", \"R2\"]]\n",
        "\n",
        "metrics_report = {\n",
        "    \"train_rows\": int(X_train.shape[0]),\n",
        "    \"test_rows\": int(X_test.shape[0]),\n",
        "    \"best_model\": best_model_name,\n",
        "    \"best_params\": search.best_params_,\n",
        "    \"baseline\": baseline_df.to_dict(orient=\"records\"),\n",
        "    \"cross_validation\": cv_results_df.to_dict(orient=\"records\"),\n",
        "    \"hyperparameter_top\": search_results_df.to_dict(orient=\"records\"),\n",
        "    \"test_metrics\": final_metrics,\n",
        "}\n",
        "\n",
        "def _json_serializer(obj):\n",
        "    if isinstance(obj, (np.integer, np.int64)):\n",
        "        return int(obj)\n",
        "    if isinstance(obj, (np.floating, np.float64)):\n",
        "        return float(obj)\n",
        "    return str(obj)\n",
        "\n",
        "metrics_path = REPORTS_DIR / \"model_metrics.json\"\n",
        "metrics_path.write_text(json.dumps(metrics_report, indent=2, default=_json_serializer))\n",
        "print(f\"Reporte de métricas exportado a {metrics_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347f9d3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_df = pd.DataFrame({\n",
        "    \"real\": y_test,\n",
        "    \"prediccion\": test_predictions\n",
        "})\n",
        "evaluation_df[\"error\"] = evaluation_df[\"prediccion\"] - evaluation_df[\"real\"]\n",
        "evaluation_df[\"abs_error\"] = evaluation_df[\"error\"].abs()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "axes[0].scatter(evaluation_df[\"real\"], evaluation_df[\"prediccion\"], alpha=0.4)\n",
        "axes[0].plot([evaluation_df[\"real\"].min(), evaluation_df[\"real\"].max()],\n",
        "             [evaluation_df[\"real\"].min(), evaluation_df[\"real\"].max()],\n",
        "             color=\"red\", linestyle=\"--\")\n",
        "axes[0].set_xlabel(\"Tarifa real\")\n",
        "axes[0].set_ylabel(\"Tarifa predicha\")\n",
        "axes[0].set_title(\"Comparación real vs predicho\")\n",
        "axes[1].hist(evaluation_df[\"error\"], bins=40, color=\"#55a868\")\n",
        "axes[1].set_title(\"Distribución de errores\")\n",
        "axes[1].set_xlabel(\"Error (pred - real)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa3fb67f",
      "metadata": {},
      "source": [
        "### 1.12 Análisis de errores e importancia de variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1298fa3",
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_view = FeatureGenerator().transform(X_test)\n",
        "\n",
        "error_analysis_df = pd.concat([feature_view.reset_index(drop=True), evaluation_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "error_by_route = error_analysis_df.groupby(\"route\")[\"abs_error\"].mean().sort_values(ascending=False).head(10)\n",
        "error_by_stops = error_analysis_df.groupby(\"is_nonstop\")[\"abs_error\"].mean()\n",
        "\n",
        "print(\"Error medio por rutas más difíciles:\\n\", error_by_route)\n",
        "print(\"Error medio por tipo de vuelo (0 = con escalas, 1 = directo):\\n\", error_by_stops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709e609e",
      "metadata": {},
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(RANDOM_STATE)\n",
        "\n",
        "def bootstrap_ci(values, metric_fn, n_bootstrap=300, alpha=0.05):\n",
        "    stats = []\n",
        "    for _ in range(n_bootstrap):\n",
        "        sample = rng.choice(values, size=len(values), replace=True)\n",
        "        stats.append(metric_fn(sample))\n",
        "    lower, upper = np.quantile(stats, [alpha / 2, 1 - alpha / 2])\n",
        "    return lower, upper\n",
        "\n",
        "mae_ci = bootstrap_ci(error_analysis_df[\"abs_error\"].values, np.mean)\n",
        "rmse_ci = bootstrap_ci(evaluation_df[\"error\"].values, lambda e: np.sqrt(np.mean(e ** 2)))\n",
        "print(f\"MAE global ±95% CI: {final_metrics['MAE']:,.0f} [{mae_ci[0]:,.0f}, {mae_ci[1]:,.0f}]\")\n",
        "print(f\"RMSE global ±95% CI: {final_metrics['RMSE']:,.0f} [{rmse_ci[0]:,.0f}, {rmse_ci[1]:,.0f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "964618fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "route_summary = (\n",
        "    error_analysis_df.groupby(\"route\")\n",
        "    .agg(soporte=(\"route\", \"size\"), mae=(\"abs_error\", \"mean\"))\n",
        "    .sort_values(\"mae\", ascending=False)\n",
        ")\n",
        "low_support = route_summary[route_summary[\"soporte\"] < 40].head(10)\n",
        "low_support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8634c70",
      "metadata": {},
      "outputs": [],
      "source": [
        "error_analysis_df[\"fare_bucket\"] = pd.qcut(\n",
        "    error_analysis_df[\"real\"], q=10, labels=False, duplicates=\"drop\"\n",
        ")\n",
        "days_bins = [-1, 3, 7, 14, 30, 60, 120]\n",
        "error_analysis_df[\"days_bucket\"] = pd.cut(error_analysis_df[\"Days_left\"], bins=days_bins)\n",
        "\n",
        "mae_by_fare = error_analysis_df.groupby(\"fare_bucket\")[\"abs_error\"].mean()\n",
        "mae_by_days = error_analysis_df.groupby(\"days_bucket\")[\"abs_error\"].mean()\n",
        "\n",
        "print(\"MAE por decil de tarifa:\")\n",
        "display(mae_by_fare)\n",
        "print(\"MAE por bucket de Days_left:\")\n",
        "display(mae_by_days)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5cebca",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_payload(date_str, airline, source, destination, flight_class, departure, arrival, total_stops, duration, days_left):\n",
        "    dt = pd.to_datetime(date_str)\n",
        "    return {\n",
        "        \"Date_of_journey\": dt.date().isoformat(),\n",
        "        \"Journey_day\": dt.strftime(\"%A\"),\n",
        "        \"Airline\": airline,\n",
        "        \"Flight_code\": None,\n",
        "        \"Class\": flight_class,\n",
        "        \"Source\": source,\n",
        "        \"Departure\": departure,\n",
        "        \"Total_stops\": total_stops,\n",
        "        \"Arrival\": arrival,\n",
        "        \"Destination\": destination,\n",
        "        \"Duration_in_hours\": duration,\n",
        "        \"Days_left\": days_left,\n",
        "    }\n",
        "\n",
        "stress_scenarios = [\n",
        "    (\n",
        "        \"Compra última hora con 2 escalas en Business\",\n",
        "        make_payload(\"2024-04-15\", \"Air India\", \"Ahmedabad\", \"Kolkata\", \"Business\", \"12 PM - 6 PM\", \"After 6 PM\", \"2+-stop\", 9.5, 0),\n",
        "    ),\n",
        "    (\n",
        "        \"Ruta poco frecuente nocturna\",\n",
        "        make_payload(\"2024-07-04\", \"GO FIRST\", \"Jaipur\", \"Chandigarh\", \"Economy\", \"After 6 PM\", \"Before 6 AM\", \"1-stop\", 6.0, 5),\n",
        "    ),\n",
        "    (\n",
        "        \"Anticipación extrema (>90 días) con vuelo directo largo\",\n",
        "        make_payload(\"2024-10-20\", \"Vistara\", \"Delhi\", \"Port Blair\", \"Business\", \"6 AM - 12 PM\", \"12 PM - 6 PM\", \"non-stop\", 5.0, 95),\n",
        "    ),\n",
        "]\n",
        "\n",
        "stress_results = []\n",
        "for label, payload in stress_scenarios:\n",
        "    pred = best_model.predict(pd.DataFrame([payload]))[0]\n",
        "    stress_results.append({\"Escenario\": label, \"Tarifa estimada (INR)\": pred, \"Days_left\": payload[\"Days_left\"], \"Total_stops\": payload[\"Total_stops\"]})\n",
        "\n",
        "pd.DataFrame(stress_results).sort_values(\"Tarifa estimada (INR)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a29d396",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_step = best_model.named_steps.get(\"model\")\n",
        "preprocessor_step = best_model.named_steps.get(\"preprocessor\")\n",
        "\n",
        "if hasattr(model_step, \"feature_importances_\"):\n",
        "    feature_names = preprocessor_step.get_feature_names_out()\n",
        "    importances = model_step.feature_importances_\n",
        "    importance_df = pd.DataFrame({\n",
        "        \"feature\": feature_names,\n",
        "        \"importance\": importances\n",
        "    }).sort_values(by=\"importance\", ascending=False).head(15)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=importance_df, x=\"importance\", y=\"feature\", palette=\"viridis\")\n",
        "    plt.title(\"Importancia de variables (top 15)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"El modelo seleccionado no expone importancias de forma nativa.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f2bfdfa",
      "metadata": {},
      "source": [
        "### 1.14 Guardado del modelo para despliegue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347f205c",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_PATH = ARTIFACTS_DIR / \"model_pipeline.joblib\"\n",
        "joblib.dump(best_model, MODEL_PATH)\n",
        "print(f\"Pipeline completo guardado en: {MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6abadfec",
      "metadata": {},
      "source": [
        "### 1.15 Propuesta de despliegue\n",
        "- **App Streamlit**: interfaz rica que puede correr en Streamlit Cloud o en un contenedor ligero. Ahora consume el pipeline local o la API externa mediante una opción en la barra lateral.\n",
        "- **API FastAPI**: servicio `uvicorn` que carga `artifacts/model_pipeline.joblib` a través de `LocalModelService` y expone `POST /predict` y `GET /health`. Esta capa permite desacoplar el frontend, automatizar pruebas y escalar horizontalmente con un balanceador.\n",
        "- **Recursos**: instancia `t3.small` (~2 vCPU/4GB) alcanza para inferencia de ~15 req/s; para mayor carga se recomienda autoscaling con un caché (Redis) para rutas populares y almacenamiento compartido del artefacto (S3 + EFS).\n",
        "- **Operación/MLOps**: ejecutar el notebook en modo batch mensual, registrar métricas en `reports/model_metrics.json`, versionar artefactos (`model_pipeline_vX.joblib`) y promover sólo si el MAE temporal mejora. Monitorear métricas por ruta, bucket de `Days_left` y drift de categorías (Airline/Class).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae116f4",
      "metadata": {},
      "source": [
        "- **API FastAPI**: levantar un servicio que cargue `artifacts/model_pipeline.joblib` y exponga `POST /predict` para recibir las características del vuelo y devolver la tarifa estimada (más un intervalo de confianza aproximado).\n",
        "- **Frontend Streamlit**: interfaz simple para que una persona ingrese aerolínea, ruta, franjas horarias, escalas, días de anticipación y duración estimada. El frontend llama a la API y muestra el resultado junto con comparaciones históricas.\n",
        "- **Operación**: el modelo se podría re-entrenar semanal o mensualmente cuando haya nuevos datos. Se recomienda empaquetar el servicio en contenedores y monitorear el MAE en producción para detectar drift.\n",
        "- **Escalabilidad**: uso de contenedores (Docker) + orquestadores (ECS/Kubernetes) y caché para rutas populares. Integración vía API Gateway o microservicio dentro de la arquitectura de la aerolínea."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16bfdf3b",
      "metadata": {},
      "source": [
        "### 1.16 Instrucciones de uso\n",
        "1. Ejecutar todas las celdas del notebook hasta guardar `artifacts/model_pipeline.joblib` y `reports/model_metrics.json`.\n",
        "2. Crear/activar el entorno virtual e instalar dependencias (`pip install -r requirements.txt`).\n",
        "3. Opcional: iniciar la API `uvicorn api.main:app --reload` para exponer `POST /predict`.\n",
        "4. Levantar la app con `streamlit run frontend/app.py` y elegir en la barra lateral si se usa el pipeline local o la API.\n",
        "5. Explorar las pestañas de *Predicción*, *What-if*, *Casos típicos* y *Análisis del dataset* para validar resultados y escenarios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0747ab",
      "metadata": {},
      "source": [
        "### 1.17 Reflexiones y próximos pasos\n",
        "- **Aprendizajes técnicos**: migramos a un pipeline centralizado reutilizable, agregamos features de calendario/temporada/feriados y validamos con `TimeSeriesSplit`. El ajuste fino vía `RandomizedSearchCV` permitió que XGBoost tuned se consolide como el mejor estimador.\n",
        "- **Relación EDA → decisiones**: el sesgo de tarifas y la dependencia con `Days_left` motivaron el uso de MAE y nuevas métricas derivadas (`duration_per_stop`, `route_class`). La curva de aprendizaje evidencia que aún hay margen con más datos recientes.\n",
        "- **Robustez**: los intervalos bootstrap y el MAE por deciles muestran estabilidad en la mayor parte del dominio, pero las rutas con poco soporte (<40 registros) exhiben errores >₹2.5K. Los stress tests sirven para monitorear escenarios fuera de distribución antes de un despliegue real.\n",
        "- **Límites y próximos pasos**: seguimos dependiendo de un dataset estático sin señales externas (feriados reales, ocupación, eventos). Siguiente paso: incorporar datos frescos en ventanas móviles, etiquetar feriados reales por año y automatizar retraining + monitoreo vía la API FastAPI construida para este prototipo.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
